{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica: Redes convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%connect_info\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST con Pytorch\n",
    "Pytorch facilita la creación de redes neuronales, como ejemplo puedes tomar la siguiente red que clasifica a los datos del conjunto MNIST haciendo uso de la arquitectura vista anteriormente: una capa de entrada con 784 neuronas, 27 neuronas en una capa oculta y una salida de 10 unidades.\n",
    "\n",
    "Para implementar una red con esta herramienta debes extender a la clase nn.Module y a sus métodos:\n",
    "- Constructor: donde estableces cuáles serán las capas que componen a la arquitectura\n",
    "- Forward: donde indicas como se conectan las capas indicadas en el constructor\n",
    "\n",
    "Ademas, para simplificar el proceso puedes agregar un metodo **train** al cual le pases el numero de iteraciones y otros parametros para entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "CRC check failed 0x3a573c47 != 0x32a662bL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bbb95c351026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Descargamos el conjunto de datos en las variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_dataset_mnist = MNIST(root='./data',train=True,download=True,\n\u001b[0;32m----> 3\u001b[0;31m                           transform=transforms.ToTensor())\n\u001b[0m\u001b[1;32m      4\u001b[0m test_dataset_mnist  = MNIST(root='./data',train=False,download=True,\n\u001b[1;32m      5\u001b[0m                           transform=transforms.ToTensor())\n",
      "\u001b[0;32m/home/christian/.local/lib/python2.7/site-packages/torchvision/datasets/mnist.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/.local/lib/python2.7/site-packages/torchvision/datasets/mnist.pyc\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# process and save as torch files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/.local/lib/python2.7/site-packages/torchvision/datasets/utils.pyc\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting {} to {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/.local/lib/python2.7/site-packages/torchvision/datasets/utils.pyc\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(from_path, to_path, remove_finished)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mto_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mout_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                     \u001b[0mreadsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_read_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muncompress\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Reached EOF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_read_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcrc32\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             raise IOError(\"CRC check failed %s != %s\" % (hex(crc32),\n\u001b[0;32m--> 353\u001b[0;31m                                                          hex(self.crc)))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffffL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Incorrect length of data produced\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: CRC check failed 0x3a573c47 != 0x32a662bL"
     ]
    }
   ],
   "source": [
    "#Descargamos el conjunto de datos en las variables.\n",
    "train_dataset_mnist = MNIST(root='./data',train=True,download=True,\n",
    "                          transform=transforms.ToTensor())\n",
    "test_dataset_mnist  = MNIST(root='./data',train=False,download=True,\n",
    "                          transform=transforms.ToTensor())\n",
    "\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "#Creamos un DataLoader,el cual nos permite iterar sobre nuestros datos y \n",
    "#administrarlos facilmente en lotes.\n",
    "train_loader_mnist  = torch.utils.data.DataLoader(dataset=train_dataset_mnist,batch_size=64,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_loader_mnist   = torch.utils.data.DataLoader(dataset=test_dataset_mnist,batch_size=64,\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mnist(batch):\n",
    "    '''Recibe un batch de informacion de MNIST y lo aplana\n",
    "    Ej: [5,28,28]-> [5,784]'''\n",
    "    return batch.view(-1,28*28)\n",
    "\n",
    "def contarCorrectas(net,batch,labels,func=None):\n",
    "    '''Dado un batch y sus etiquetas, cuenta el numero de respuestas\n",
    "    correctas de una red, el parametro func aplica una modificacion al \n",
    "    tensor que contiene los datos'''\n",
    "    \n",
    "    if(func!=None):\n",
    "        batch=func(batch)\n",
    "        salidas=net(batch)\n",
    "    else:\n",
    "        salidas=net(batch)\n",
    "    respuestas=salidas.max(dim=1)[1]\n",
    "    cantidadCorrectas=(respuestas==labels).sum()\n",
    "    return cantidadCorrectas\n",
    "    \n",
    "def calcularPrecisionGlobal(net,data_loader,batch_size,func=None,cuda=False):\n",
    "    '''Calcula la precision de una red dado un data_loader,\n",
    "    recive una funcion que transforma los datos en caso de ser necesario'''\n",
    "    correctas=0\n",
    "    for (images,labels) in data_loader:\n",
    "        if(cuda and torch.cuda.is_available()):\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "        correctas+=contarCorrectas(net,images,labels,func)        \n",
    "    correctas=correctas.data.tolist()\n",
    "    return (100*correctas)/(len(data_loader)*batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestro modelo debe heredar de nn.Module\n",
    "class MNIST_NET(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(MNIST_NET,self).__init__()\n",
    "        #Definimos nuestras unidades de entrada y las agregamos al objeto actual\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size,bias=True)\n",
    "        self.sig1= nn.Sigmoid() \n",
    "        self.fc2 = nn.Linear(hidden_size,num_classes,bias=True)        \n",
    "    \n",
    "    def forward(self,input_data):\n",
    "        '''Definimos como seran procesados los datos de entrada'''\n",
    "        out=self.fc1(input_data) #Primero se hacen pasar por la capa lineal\n",
    "        out=self.sig1(out)       #Despues,la salida para por la funcion sigmode\n",
    "        out=self.fc2(out)        #La salida finalmente pasa por otra capa lineal\n",
    "        return out\n",
    "\n",
    "    def train(self,epochs,data_loader,criterion,optimizer,cuda=False):\n",
    "        '''Entrena la red net, por un numero de epocas \"epochs\" con el data_loader\n",
    "        proporcionado,usando como funcion de perdida la definida en \"criterion\" y el\n",
    "        optimizador pasado como parametro'''\n",
    "        for epoch in range(epochs):\n",
    "            for i,(images,labels) in enumerate(data_loader):\n",
    "\n",
    "                images = Variable(images.view(-1,28*28))#aplanamos el batch actual\n",
    "                labels = Variable(labels.view(-1,))     #convertimos el tensor a un tensor de valores unitarios\n",
    "                if(cuda and torch.cuda.is_available()): #Si nuestra PC cuenta con GPU,realizamos calculos en ella\n",
    "                    images=images.cuda()\n",
    "                    labels=labels.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs= self(images)#llamar a nuestro objeto con parametros es introducirlos a la red\n",
    "                loss   = criterion(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if (epoch) % 2 == 0:                              # Logging\n",
    "                print('Epoch [%d/%d], Step %d, Loss: %.4f'\n",
    "                 %(epoch, epochs, i+1, loss.item()))\n",
    "            \n",
    "#Instanciamos la red que ya conocemos para MNIST de 28*28 --> 27 --> 10\n",
    "Red =MNIST_NET(28*28,27,10)\n",
    "#Red.cuda() #puedes descomentar esta linea si tienes GPU disponible\n",
    "#Escogemos la funcion de error para el modelo (entropia cruzada)\n",
    "criterio   = nn.CrossEntropyLoss()\n",
    "optimizer  = torch.optim.SGD(Red.parameters(),lr=0.001)\n",
    "#Entrenamos la red durante 100 pasos,con entropia cruzada y SGD \n",
    "Red.train(25,train_loader_mnist,criterio,optimizer,cuda=False) #puedes agregar cuda=true si tienes GPU disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_train =calcularPrecisionGlobal(Red,train_loader_mnist,64,func=reshape_mnist,cuda=False)\n",
    "prec_val   =calcularPrecisionGlobal(Red,test_loader_mnist,64,func=reshape_mnist,cuda=False)\n",
    "print(\"Precision en conjunto de entrenamiento: %.4f%%\"%(prec_train))\n",
    "print(\"Precision en conjunto de validacion: %.4f%%\"%(prec_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar 10 y redes convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura que deberas implementar debe tener las siguientes caracteristicas:\n",
    "\n",
    "    - Una capa convolucional de entrada con un filtro de 5x5x3 y 64 filtros de salida\n",
    "    - Una capa de MaxPooling \n",
    "    - Otra capa convolucional con un filtro de 5x5x64 y 64 filtros de salida\n",
    "    - Una capa de MaxPooling\n",
    "    - Una capa completamente conectada con 384 neuronas,cuya activacion es ReLu\n",
    "    - Una capa completamente conectada con 192 neuronas,cuya activacion es ReLu\n",
    "    -Finalmente,una capa de salida con 10 neuronas\n",
    "Es importante señalar que entre cada capa convolucional y de pooling existe una activacion **ReLu**\n",
    "\n",
    "Graficamente, algo similar a lo mostrado en la siguiente figura:\n",
    "<img src=\"AlexNet-cifar10.png\" alt=\"Arquitectura de la red\" title=\"Red convolucional\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar 10\n",
    "Es un conjunto de datos de imagenes que tiene 60,000 imagenes de 30x30 a color de 10 clases distintas (cada clase con 6,000 imagenes).\n",
    "Las clases de este conjunto de datos corresponden a:\n",
    "airplane, automobile, bird, cat, deer, dog, frog, horse, ship, y truck.\n",
    "\n",
    "Para clasificar este conjunto de datos usaremos una red convolucional anteriormente descrita en Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos de este conjunto en las variables correspondientes al igual que el caso de MNIST\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6699196b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_imshow_format(image):\n",
    "    image = image / 2 + 0.5\n",
    "    image = image.numpy()\n",
    "    return image.transpose(1,2,0)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(12,2.5))\n",
    "for idx, image in enumerate(images):\n",
    "    axes[idx].imshow(convert_to_imshow_format(image))\n",
    "    axes[idx].set_title(classes[labels[idx]])\n",
    "    axes[idx].set_xticks([])\n",
    "    axes[idx].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
    "import torch.nn.functional as F\n",
    "class CIFAR_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''Constructor de la red neuronal\n",
    "        En esta funcion defines las operaciones que seran realizadas y \n",
    "        las agregas a self para tenerlas disponibles despues'''\n",
    "        super(CIFAR_NET, self).__init__()\n",
    "        \n",
    "        #Toma en cuenta el constructor de las capas convolucionales\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,\n",
    "        #                   padding=0, dilation=1, groups=1, bias=True)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        #Una capa de neuronas  se declara con:\n",
    "        #nn.Linear(in_features= x ,out_features=y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Ejecuta forward sobre los datos de entrada x\n",
    "        En esta funcion debes definir de manera consecutiva el orden\n",
    "        de las operaciones capa por capa que definiste en el constructor y\n",
    "        devolver el resultado'''\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self,epochs,data_loader,criterion,optimizer,cuda=False):\n",
    "        '''Entrena la red net, por un numero de epocas \"epochs\" con el data_loader\n",
    "        proporcionado,usando como funcion de perdida la definida en \"criterion\" y el\n",
    "        optimizador pasado como parametro'''\n",
    "        \n",
    "        #Primero itera sobre el numero de epocas de entrenamiento\n",
    "       \n",
    "            \n",
    "        #Despues,para cada epoca de entrenamiento recorre los datos del dataloader\n",
    "           \n",
    "        #Recuerda incluir una manera de monitorizar el desempeño actual de la red\n",
    "        #Es util mostrar el valor actual de perdida y de precision\n",
    "        for epoch in range(epochs):\n",
    "            actual_loss = 0.0\n",
    "            for i, data in enumerate(data_loader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                actual_loss += loss.item()\n",
    "                \n",
    "                if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, actual_loss / 2000))\n",
    "                    actual_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.301\n",
      "[1,  4000] loss: 2.138\n",
      "[1,  6000] loss: 1.908\n",
      "[1,  8000] loss: 1.772\n",
      "[1, 10000] loss: 1.664\n",
      "[1, 12000] loss: 1.612\n",
      "[2,  2000] loss: 1.550\n",
      "[2,  4000] loss: 1.502\n",
      "[2,  6000] loss: 1.483\n",
      "[2,  8000] loss: 1.458\n",
      "[2, 10000] loss: 1.423\n",
      "[2, 12000] loss: 1.410\n",
      "[3,  2000] loss: 1.346\n",
      "[3,  4000] loss: 1.327\n",
      "[3,  6000] loss: 1.334\n",
      "[3,  8000] loss: 1.332\n",
      "[3, 10000] loss: 1.317\n",
      "[3, 12000] loss: 1.299\n",
      "[4,  2000] loss: 1.224\n",
      "[4,  4000] loss: 1.220\n",
      "[4,  6000] loss: 1.222\n",
      "[4,  8000] loss: 1.236\n",
      "[4, 10000] loss: 1.223\n",
      "[4, 12000] loss: 1.224\n",
      "[5,  2000] loss: 1.150\n",
      "[5,  4000] loss: 1.163\n",
      "[5,  6000] loss: 1.137\n",
      "[5,  8000] loss: 1.158\n",
      "[5, 10000] loss: 1.175\n",
      "[5, 12000] loss: 1.165\n",
      "[6,  2000] loss: 1.072\n",
      "[6,  4000] loss: 1.097\n",
      "[6,  6000] loss: 1.107\n",
      "[6,  8000] loss: 1.119\n",
      "[6, 10000] loss: 1.100\n",
      "[6, 12000] loss: 1.104\n",
      "[7,  2000] loss: 1.029\n",
      "[7,  4000] loss: 1.054\n",
      "[7,  6000] loss: 1.063\n",
      "[7,  8000] loss: 1.041\n",
      "[7, 10000] loss: 1.039\n",
      "[7, 12000] loss: 1.088\n",
      "[8,  2000] loss: 0.975\n",
      "[8,  4000] loss: 0.992\n",
      "[8,  6000] loss: 1.026\n",
      "[8,  8000] loss: 1.019\n",
      "[8, 10000] loss: 1.024\n",
      "[8, 12000] loss: 1.032\n",
      "[9,  2000] loss: 0.940\n",
      "[9,  4000] loss: 0.969\n",
      "[9,  6000] loss: 0.970\n",
      "[9,  8000] loss: 0.978\n",
      "[9, 10000] loss: 0.992\n",
      "[9, 12000] loss: 0.992\n",
      "[10,  2000] loss: 0.911\n",
      "[10,  4000] loss: 0.923\n",
      "[10,  6000] loss: 0.945\n",
      "[10,  8000] loss: 0.941\n",
      "[10, 10000] loss: 0.955\n",
      "[10, 12000] loss: 0.957\n",
      "[11,  2000] loss: 0.878\n",
      "[11,  4000] loss: 0.902\n",
      "[11,  6000] loss: 0.899\n",
      "[11,  8000] loss: 0.921\n",
      "[11, 10000] loss: 0.942\n",
      "[11, 12000] loss: 0.927\n",
      "[12,  2000] loss: 0.825\n",
      "[12,  4000] loss: 0.868\n",
      "[12,  6000] loss: 0.882\n",
      "[12,  8000] loss: 0.889\n",
      "[12, 10000] loss: 0.929\n",
      "[12, 12000] loss: 0.908\n",
      "[13,  2000] loss: 0.801\n",
      "[13,  4000] loss: 0.837\n",
      "[13,  6000] loss: 0.849\n",
      "[13,  8000] loss: 0.882\n",
      "[13, 10000] loss: 0.882\n",
      "[13, 12000] loss: 0.899\n",
      "[14,  2000] loss: 0.802\n",
      "[14,  4000] loss: 0.813\n",
      "[14,  6000] loss: 0.829\n",
      "[14,  8000] loss: 0.864\n",
      "[14, 10000] loss: 0.866\n",
      "[14, 12000] loss: 0.871\n",
      "[15,  2000] loss: 0.758\n",
      "[15,  4000] loss: 0.791\n",
      "[15,  6000] loss: 0.817\n",
      "[15,  8000] loss: 0.837\n",
      "[15, 10000] loss: 0.872\n",
      "[15, 12000] loss: 0.855\n",
      "[16,  2000] loss: 0.746\n",
      "[16,  4000] loss: 0.768\n",
      "[16,  6000] loss: 0.810\n",
      "[16,  8000] loss: 0.825\n",
      "[16, 10000] loss: 0.818\n",
      "[16, 12000] loss: 0.828\n",
      "[17,  2000] loss: 0.740\n",
      "[17,  4000] loss: 0.745\n",
      "[17,  6000] loss: 0.771\n",
      "[17,  8000] loss: 0.802\n",
      "[17, 10000] loss: 0.808\n",
      "[17, 12000] loss: 0.826\n",
      "[18,  2000] loss: 0.709\n",
      "[18,  4000] loss: 0.749\n",
      "[18,  6000] loss: 0.762\n",
      "[18,  8000] loss: 0.819\n",
      "[18, 10000] loss: 0.791\n",
      "[18, 12000] loss: 0.804\n",
      "[19,  2000] loss: 0.696\n",
      "[19,  4000] loss: 0.738\n",
      "[19,  6000] loss: 0.771\n",
      "[19,  8000] loss: 0.781\n",
      "[19, 10000] loss: 0.802\n",
      "[19, 12000] loss: 0.774\n",
      "[20,  2000] loss: 0.679\n",
      "[20,  4000] loss: 0.727\n",
      "[20,  6000] loss: 0.739\n",
      "[20,  8000] loss: 0.772\n",
      "[20, 10000] loss: 0.769\n",
      "[20, 12000] loss: 0.780\n",
      "[21,  2000] loss: 0.688\n",
      "[21,  4000] loss: 0.691\n",
      "[21,  6000] loss: 0.713\n",
      "[21,  8000] loss: 0.748\n",
      "[21, 10000] loss: 0.769\n",
      "[21, 12000] loss: 0.787\n",
      "[22,  2000] loss: 0.691\n",
      "[22,  4000] loss: 0.697\n",
      "[22,  6000] loss: 0.752\n",
      "[22,  8000] loss: 0.745\n",
      "[22, 10000] loss: 0.761\n",
      "[22, 12000] loss: 0.751\n",
      "[23,  2000] loss: 0.646\n",
      "[23,  4000] loss: 0.698\n",
      "[23,  6000] loss: 0.687\n",
      "[23,  8000] loss: 0.715\n",
      "[23, 10000] loss: 0.748\n",
      "[23, 12000] loss: 0.773\n",
      "[24,  2000] loss: 0.628\n",
      "[24,  4000] loss: 0.689\n",
      "[24,  6000] loss: 0.696\n",
      "[24,  8000] loss: 0.734\n",
      "[24, 10000] loss: 0.753\n",
      "[24, 12000] loss: 0.746\n",
      "[25,  2000] loss: 0.646\n",
      "[25,  4000] loss: 0.647\n",
      "[25,  6000] loss: 0.708\n",
      "[25,  8000] loss: 0.697\n",
      "[25, 10000] loss: 0.750\n",
      "[25, 12000] loss: 0.754\n",
      "[26,  2000] loss: 0.623\n",
      "[26,  4000] loss: 0.651\n",
      "[26,  6000] loss: 0.688\n",
      "[26,  8000] loss: 0.756\n",
      "[26, 10000] loss: 0.721\n",
      "[26, 12000] loss: 0.712\n",
      "[27,  2000] loss: 0.639\n",
      "[27,  4000] loss: 0.659\n",
      "[27,  6000] loss: 0.692\n",
      "[27,  8000] loss: 0.711\n",
      "[27, 10000] loss: 0.721\n",
      "[27, 12000] loss: 0.723\n",
      "[28,  2000] loss: 0.621\n",
      "[28,  4000] loss: 0.664\n",
      "[28,  6000] loss: 0.658\n",
      "[28,  8000] loss: 0.705\n",
      "[28, 10000] loss: 0.739\n",
      "[28, 12000] loss: 0.721\n",
      "[29,  2000] loss: 0.616\n",
      "[29,  4000] loss: 0.653\n",
      "[29,  6000] loss: 0.688\n",
      "[29,  8000] loss: 0.705\n",
      "[29, 10000] loss: 0.703\n",
      "[29, 12000] loss: 0.721\n",
      "[30,  2000] loss: 0.587\n",
      "[30,  4000] loss: 0.639\n",
      "[30,  6000] loss: 0.640\n",
      "[30,  8000] loss: 0.697\n",
      "[30, 10000] loss: 0.737\n",
      "[30, 12000] loss: 0.728\n",
      "[31,  2000] loss: 0.618\n",
      "[31,  4000] loss: 0.618\n",
      "[31,  6000] loss: 0.667\n",
      "[31,  8000] loss: 0.675\n",
      "[31, 10000] loss: 0.713\n",
      "[31, 12000] loss: 0.708\n",
      "[32,  2000] loss: 0.613\n",
      "[32,  4000] loss: 0.618\n",
      "[32,  6000] loss: 0.694\n",
      "[32,  8000] loss: 0.669\n",
      "[32, 10000] loss: 0.717\n",
      "[32, 12000] loss: 0.696\n",
      "[33,  2000] loss: 0.622\n",
      "[33,  4000] loss: 0.606\n",
      "[33,  6000] loss: 0.658\n",
      "[33,  8000] loss: 0.683\n",
      "[33, 10000] loss: 0.690\n",
      "[33, 12000] loss: 0.707\n",
      "[34,  2000] loss: 0.584\n",
      "[34,  4000] loss: 0.646\n",
      "[34,  6000] loss: 0.645\n",
      "[34,  8000] loss: 0.683\n",
      "[34, 10000] loss: 0.683\n",
      "[34, 12000] loss: 0.704\n",
      "[35,  2000] loss: 0.562\n",
      "[35,  4000] loss: 0.641\n",
      "[35,  6000] loss: 0.652\n",
      "[35,  8000] loss: 0.657\n",
      "[35, 10000] loss: 0.719\n",
      "[35, 12000] loss: 0.700\n",
      "[36,  2000] loss: 0.585\n",
      "[36,  4000] loss: 0.603\n",
      "[36,  6000] loss: 0.652\n",
      "[36,  8000] loss: 0.656\n",
      "[36, 10000] loss: 0.707\n",
      "[36, 12000] loss: 0.697\n",
      "[37,  2000] loss: 0.548\n",
      "[37,  4000] loss: 0.645\n",
      "[37,  6000] loss: 0.667\n",
      "[37,  8000] loss: 0.671\n",
      "[37, 10000] loss: 0.687\n",
      "[37, 12000] loss: 0.699\n",
      "[38,  2000] loss: 0.596\n",
      "[38,  4000] loss: 0.631\n",
      "[38,  6000] loss: 0.674\n",
      "[38,  8000] loss: 0.689\n",
      "[38, 10000] loss: 0.667\n",
      "[38, 12000] loss: 0.727\n",
      "[39,  2000] loss: 0.583\n",
      "[39,  4000] loss: 0.616\n",
      "[39,  6000] loss: 0.649\n",
      "[39,  8000] loss: 0.683\n",
      "[39, 10000] loss: 0.671\n",
      "[39, 12000] loss: 0.711\n",
      "[40,  2000] loss: 0.586\n",
      "[40,  4000] loss: 0.635\n",
      "[40,  6000] loss: 0.654\n",
      "[40,  8000] loss: 0.680\n",
      "[40, 10000] loss: 0.668\n",
      "[40, 12000] loss: 0.682\n",
      "[41,  2000] loss: 0.608\n",
      "[41,  4000] loss: 0.614\n",
      "[41,  6000] loss: 0.643\n",
      "[41,  8000] loss: 0.683\n",
      "[41, 10000] loss: 0.685\n",
      "[41, 12000] loss: 0.679\n",
      "[42,  2000] loss: 0.567\n",
      "[42,  4000] loss: 0.628\n",
      "[42,  6000] loss: 0.635\n",
      "[42,  8000] loss: 0.646\n",
      "[42, 10000] loss: 0.668\n",
      "[42, 12000] loss: 0.687\n",
      "[43,  2000] loss: 0.536\n",
      "[43,  4000] loss: 0.626\n",
      "[43,  6000] loss: 0.627\n",
      "[43,  8000] loss: 0.685\n",
      "[43, 10000] loss: 0.690\n",
      "[43, 12000] loss: 0.691\n",
      "[44,  2000] loss: 0.615\n",
      "[44,  4000] loss: 0.614\n",
      "[44,  6000] loss: 0.630\n",
      "[44,  8000] loss: 0.660\n",
      "[44, 10000] loss: 0.659\n",
      "[44, 12000] loss: 0.684\n",
      "[45,  2000] loss: 0.564\n",
      "[45,  4000] loss: 0.631\n",
      "[45,  6000] loss: 0.647\n",
      "[45,  8000] loss: 0.654\n",
      "[45, 10000] loss: 0.691\n",
      "[45, 12000] loss: 0.676\n",
      "[46,  2000] loss: 0.569\n",
      "[46,  4000] loss: 0.617\n",
      "[46,  6000] loss: 0.604\n",
      "[46,  8000] loss: 0.662\n",
      "[46, 10000] loss: 0.653\n",
      "[46, 12000] loss: 0.698\n",
      "[47,  2000] loss: 0.566\n",
      "[47,  4000] loss: 0.607\n",
      "[47,  6000] loss: 0.620\n",
      "[47,  8000] loss: 0.654\n",
      "[47, 10000] loss: 0.662\n",
      "[47, 12000] loss: 0.687\n",
      "[48,  2000] loss: 0.580\n",
      "[48,  4000] loss: 0.588\n",
      "[48,  6000] loss: 0.639\n",
      "[48,  8000] loss: 0.684\n",
      "[48, 10000] loss: 0.668\n",
      "[48, 12000] loss: 0.675\n",
      "[49,  2000] loss: 0.580\n",
      "[49,  4000] loss: 0.620\n",
      "[49,  6000] loss: 0.635\n",
      "[49,  8000] loss: 0.623\n",
      "[49, 10000] loss: 0.691\n",
      "[49, 12000] loss: 0.693\n",
      "[50,  2000] loss: 0.573\n",
      "[50,  4000] loss: 0.605\n",
      "[50,  6000] loss: 0.644\n",
      "[50,  8000] loss: 0.687\n",
      "[50, 10000] loss: 0.656\n",
      "[50, 12000] loss: 0.723\n"
     ]
    }
   ],
   "source": [
    "RedCIFAR=CIFAR_NET()\n",
    "#RedCIFAR.cuda() #puedes descomentar esta linea si tienes GPU disponible\n",
    "#Define el criterio que usaras para evaluar a la red y un optimizador\n",
    "\n",
    "#Entrenamos la red durante 50 pasos(o los que consideres necesarios),con entropia cruzada y el optimizador \n",
    "RedCIFAR.train(50,trainloader,nn.CrossEntropyLoss(),optim.SGD(RedCIFAR.parameters(), lr=0.001, momentum=0.9),cuda=False) #puedes agregar cuda=True si tienes GPU disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision en conjunto de entrenamiento: 76.0000%\n",
      "Precision en conjunto de validacion: 56.0000%\n"
     ]
    }
   ],
   "source": [
    "prec_train =calcularPrecisionGlobal(RedCIFAR,trainloader,4)\n",
    "prec_val   =calcularPrecisionGlobal(RedCIFAR,testloader,4)\n",
    "print(\"Precision en conjunto de entrenamiento: %.4f%%\"%(prec_train))\n",
    "print(\"Precision en conjunto de validacion: %.4f%%\"%(prec_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios:\n",
    "    -- Crea las funciones necesarias para poder introducir datos concretos a la red (una vez ya entrenada) y obtener el resultado que esta devuelve.\n",
    "    -- Con la red neuronal entrenada obten la matriz de confusion de ambos conjuntos (entrenamiento y prueba) con las 10 clases posibles y muestrala.\n",
    "    \n",
    "## Extra:\n",
    "    -- Despues de cada MaxPool normaliza las salidas y contrasta el rendimiento de la red.\n",
    "    -- Graficar las imagenes del conjunto de datos bajo demanda.\n",
    "    -- Muestra los filtros aprendidos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
